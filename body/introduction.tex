\chapter{Introduction}
Generative models have become indispensable tools for learning complex data distributions and generating new samples that resemble the original dataset. In the quantum domain, these models take on heightened significance as they leverage the inherently probabilistic nature of quantum systems to capture and reproduce "quantum data." By exploiting quantum mechanics, these models can encode probability distributions that are inaccessible to classical approaches, offering efficient sampling mechanisms and paving the way for diverse applications in physics \cite{perdomo-ortiz_opportunities_2018, noauthor_born_nodate, sweke_quantum_2021, gao_enhancing_2022}, .

Two prominent quantum generative models stand out for their physical foundations: Boltzmann machines and Born machines. Boltzmann machines utilize the Boltzmann distribution from statistical mechanics to represent joint probability distributions \cite{hinton_learning_1986}, while Born machines rely on Born's rule, encoding probabilities as squared amplitudes of wavefunctions \cite{liu_differentiable_2018, han_unsupervised_2018, perdomo-ortiz_opportunities_2018, noauthor_born_nodate}.

Despite their promise, quantum generative models face significant challenges, particularly in scalability. Issues such as barren plateaus and loss concentration —regions where gradients vanish exponentially— hinder effective training of large-scale systems\cite{rudolph_trainability_2024}. To address these limitations, Tensor Network Born Machines\cite{han_unsupervised_2018,cheng_tree_2019,meiburg_generative_2024,ben-dov_regularized_2025} (TNBMs) have emerged as a robust alternative. By incorporating tensor networks into the Born machine framework, TNBMs mitigate barren plateau problems while maintaining the expressivity advantages of quantum-inspired models \cite{martin_barren_2023}. This approach represents a critical step forward in overcoming trainability barriers and enhancing the performance of quantum generative models.

In this my master thesis, we explore the theoretical foundations and practical implementations of Tensor Network Born Machines, demonstrating their ability to model complex quantum data distributions while addressing key scalability challenges.

Traditional Born machines often rely on projective measurements in the computational basis, which restrict the information extracted during training. Inspired by classical shadow tomography techniques and previous work \cite{rudolph_generation_2022, levy_classical_2024, jerbi_shadows_2024}, we adopt positive operator-valued measures (POVMs) to perform informationally complete measurements\cite{mangini_low-variance_2024, garcia-perez_learning_2021, han_unsupervised_2018}. By sampling from a diverse set of observables, POVMs enable efficient reconstruction of quantum states and their underlying distributions. This approach captures higher-order correlations in the data, overcoming the limitations of fixed-basis measurements and ensuring robust learning of complex probability distributions.\cite{meiburg_generative_2024, rudolph_generation_2022, puljak_tn4ml_2025}